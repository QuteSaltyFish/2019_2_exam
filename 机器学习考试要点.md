# 机器学习考试要点
## 任课教师 倪冰冰（机器学习两个班级期末考试题不同）

## 一、基本概念

1、训练样本 测试样本 必须是独立同分布 iiid

2、训练集 测试集的划分 分别的特征 性能

3、函数拟合

4、训练一个分类器目标是什么？是训练误差还是测试误差还是？ 是泛化误差！

5、$ error=V+B+N $  V过拟合 B欠拟合 打靶图

6、评判标准 TTFFTFFT 错判对对判错......ROC曲线 各种曲线



## 二、回归

1、线性回归 定义：参数是一阶就是线性回归：

方法有：梯度下降（迭代）/解线性矩阵方程（伪逆矩阵）（数值不一定稳定）

error会垂直于所有样本存在的平面

正则化项形状L1，L2 （L2假设分布属于高斯分布）圆形 菱形 椭圆去相交 大多数是0 稀疏

2、逻辑回归用来做分类/也可用来做回归/sigmoid



## 三、分类

1、KNN分类算法 并行串行 并行算法怎么做:可以利用类似于Map Reduce的思想：把训练集分成很多小块，求测试样本和每个小块里的样本的距离，然后再把结果汇总。

2、贝叶斯 先验和likelyhood 曲线移动时分类面的变化: 

3、最重要的支持向量机（大题）：支撑向量/划分平面，线性，如果线性不可分的话则换成非线性kernel ，基于松弛变量的SVM，C的变化。哪个是支撑向量，哪个是远离的。

4、决策树概念，分叉方法（任何分类标准），信息熵增益（Information Gain），多棵树数据采样，再融合判断（集成学习方法）弱分类器的结构并非一种类型。

5、LDA 能降维 拍到一个方向上，同类相近异类远



## 非监督学习

### 聚类 

1、K-means必考 下降 loss function K-means可以并行计算 分布式伪代码:
Mini Batch K-Means:每次重新计算距离的时候进行无回放的随机采样。

2、GMM 使得每个样本的组别有一个概率 很尖锐的时候退化成K-means

### 数据降维

1、PCA降维，椭圆的最长轴，保留多少能量 如果所有的方向都保留 仅仅相当于旋转了则信息不损失

​	重建原则（重建时损失尽可能小）/LLE/MDS结构不变原则 （距离和邻接结构）以下有哪几个有矩阵分解结构有可能选四个嗷



## 神经网络

前向后向怎么算的 写式子

 Dropout对应的是什么原理

Relu LeakyRelu